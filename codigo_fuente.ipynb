{"cells":[{"cell_type":"markdown","source":["# **Librerías**"],"metadata":{"id":"JNtXMaXFVQfi"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2647,"status":"ok","timestamp":1652129645934,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"},"user_tz":-120},"id":"ogYRoVh7x72t","outputId":"e60a0224-6a73-4108-d475-b551cc50d070"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["#Realizamos todos los imports necesarios\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os \n","os.chdir(\"/content/drive/MyDrive/PLN/PracticaFinal\")\n","\n","import pandas as pd\n","\n","import nltk\n","from nltk import WordPunctTokenizer\n","\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stops_words = stopwords.words('spanish')\n","#Añadimos los signos de puntuación más relevantes a las palabras vacías (lo de 'b' y 'r' es por un caracter residual que queda al hacer la lectura por bytes)\n","stops_words.extend(('.', ',', ':', ';', '?', '!', '-', '``', \"''\", '--', \"'\", \"/\", \"(\", \")\", '\"', \"\\\\\", \"\\\\'\", \"...\", 'b', 'r'))\n","\n","from nltk.stem.snowball import SnowballStemmer\n","stemmer = SnowballStemmer(\"spanish\")\n","\n","from sklearn import svm\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"markdown","source":["# **Funciones**"],"metadata":{"id":"ccYegsOfVtBR"}},{"cell_type":"markdown","source":["\n","\n","##   Función para leer los ficheros .tsv\n","\n"],"metadata":{"id":"05o67wqaV6_m"}},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1652129645935,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"},"user_tz":-120},"id":"69_ezhaFyYdZ"},"outputs":[],"source":["def leerCorpus(nombre_fichero):\n","  #Leemos el fichero tsv de entrenamiento, poniendo como parámetros su nombre,\n","  #un delimitador de columnas y un encoding para que detecte el formato del texto\n","  df = pd.read_csv(nombre_fichero, delimiter='\\t', encoding='unicode_escape')   #unicode_escape\n","\n","  id = []\n","  comment = []\n","  label = []\n","  gender = []\n","  media = []\n","\n","  #Pasamos la información de las columnas a listas\n","  for i in range (len(df.index)):\n","    #print(df.iloc[:, 0][i])\n","    id.append(df.iloc[:, 0][i])\n","    correccion = correccionCodificacion(df.iloc[:, 1][i])\n","    comment.append(correccion)\n","    label.append(df.iloc[:, 2][i])\n","    gender.append(df.iloc[:, 3][i])\n","    media.append(df.iloc[:, 4][i])\n","\n","  #Creamos un diccionario con los textos y los géneros\n","  doc = {\n","    \"id\": id,\n","    \"comment\": comment,\n","    \"label\": label,\n","    \"gender\": gender,\n","    \"media\":media\n","  }\n","\n","  return doc \n"]},{"cell_type":"markdown","source":["\n","\n","\n","##   Función para procesar el texto\n","\n","\n","\n"],"metadata":{"id":"3iFpEm-aWJMK"}},{"cell_type":"code","source":["def procesarTexto(texto):\n","\n","  #Tokenizamos (he elegido este tokenizador por la separación qque hace de la puntuación)\n","  tokens = WordPunctTokenizer().tokenize(texto)\n","\n","  #Cambiamos todos los tokens a minúsculas\n","  tokens_minus = []\n","  for word in tokens:\n","    tokens_minus.append(word.lower())\n","\n","  #Eliminamos palabras vacías\n","  tokens_filtrados = [word for word in tokens_minus if word not in stops_words]\n","\n","  #Reducimos las palabras a su raiz\n","  tokens_reducidos = \"\"\n","  for word in tokens_filtrados:\n","    tokens_reducidos = tokens_reducidos + stemmer.stem(word) + \" \"\n","    #tokens_reducidos.append(stemmer.stem(word))\n","\n","  return tokens_reducidos\n","\n","#texto_procesado = procesarTexto(doc[\"comment\"][12]) \n"],"metadata":{"id":"uFwmIt4NIJ_b","executionInfo":{"status":"ok","timestamp":1652129645936,"user_tz":-120,"elapsed":10,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","\n","##   Función para corregir la mala lectura de los ficheros\n","\n","\n"],"metadata":{"id":"KEal7k_dWUKx"}},{"cell_type":"code","source":["def correccionCodificacion(cadena):\n","  corregida = \"\"\n","\n","  for word in cadena.split(' '):\n","    if 'Ã­' in word:\n","      aux = word.replace('Ã', 'í')\n","      corregida += aux + \" \"\n","    elif 'Ã¡' in word:\n","      aux = word.replace('Ã¡', 'á')\n","      corregida += aux + \" \"\n","    elif 'Ãº' in word:\n","      aux = word.replace('Ãº', 'ú')\n","      corregida += aux + \" \"\n","    elif 'Ã©' in word:\n","      aux = word.replace('Ã©', 'é')\n","      corregida += aux + \" \"\n","    elif 'Ã³' in word:\n","      aux = word.replace('Ã³', 'ó')\n","      corregida += aux + \" \"\n","    elif 'Ã±' in word:\n","      aux = word.replace('Ã±', 'ñ')\n","      corregida += aux + \" \"\n","    else:\n","      corregida += word + \" \"\n","\n","  return corregida\n","\n"],"metadata":{"id":"YLxYaOH8gZuK","executionInfo":{"status":"ok","timestamp":1652129645936,"user_tz":-120,"elapsed":10,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# **Código principal**"],"metadata":{"id":"-nFcN6q_W086"}},{"cell_type":"markdown","source":["\n","##  Leemos y procesamos el fichero de entrenamiento\n","\n"],"metadata":{"id":"6uWrkA5FW7aX"}},{"cell_type":"code","source":["#Leemos el corpus\n","doc = leerCorpus(\"train.tsv\")\n","\n","#Procesamos los textos leidos del corpus\n","textos = []\n","for i in doc[\"comment\"]:\n","  texto_procesado = procesarTexto(str(i))\n","  textos.append(texto_procesado)\n","\n","#Actualizamos los textos en el diccionario\n","doc[\"comment_procesados\"] = textos\n"],"metadata":{"id":"RNlp917jnv5c","executionInfo":{"status":"ok","timestamp":1652129663860,"user_tz":-120,"elapsed":17932,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","##   Leemos el fichero para la evaluación\n","\n"],"metadata":{"id":"jB8Ym5SoY5d4"}},{"cell_type":"code","source":["#Leemos el corpus test para predecir el genero de la persona que los ha escrito\n","fichero_test = leerCorpus(\"test.tsv\")\n","\n","#Procesamos los textos leidos del corpus\n","textos_test = []\n","for i in fichero_test[\"comment\"]:\n","  texto_procesado = procesarTexto(str(i))\n","  textos_test.append(texto_procesado)\n","\n","#Actualizamos los textos en el diccionario\n","fichero_test[\"comment_procesados\"] = textos_test"],"metadata":{"id":"V7tqVEDGZm5_","executionInfo":{"status":"ok","timestamp":1652129678372,"user_tz":-120,"elapsed":14519,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","##   Entrenamos el modelo\n","\n"],"metadata":{"id":"Y4NqQCESXJSg"}},{"cell_type":"code","source":["#Entrenamos al modelo\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(doc[\"comment_procesados\"])\n","\n","model = svm.SVC()\n","model.fit(X, doc[\"label\"])"],"metadata":{"id":"YtQnFeiiXGyh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652129743994,"user_tz":-120,"elapsed":65628,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}},"outputId":"75823128-a653-4d78-c57c-e33085b3f320"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC()"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Creamos fichero de salida"],"metadata":{"id":"K4QrZn4maDb_"}},{"cell_type":"code","source":["#Creamos el fichero y preparamos la primera fila (títulos)\n","f = open(\"prediction_test.tsv\", \"w\")\n","f.write(\"comment_id\\tpred\")"],"metadata":{"id":"T4MG5WAPZs6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652129743997,"user_tz":-120,"elapsed":14,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}},"outputId":"ba5af6c6-f07e-49ac-cf7f-1c441b353e21"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["## Hacemos predicción y anotamos resultados en fichero de salida"],"metadata":{"id":"_8T4DkrpZw5Q"}},{"cell_type":"code","source":["cont = 0\n","\n","#Realizamos la predicción y la anotamos en un fichero\n","for comentario in fichero_test[\"comment_procesados\"]:\n","  text = [comentario]\n","\n","  Y = vectorizer.transform(text)\n","  prediction = model.predict(Y)\n","\n","  #Eliminamos los caracteres que no nos interesan de la predicción\n","  caracteres = \"[']\"\n","  prediccion = ''.join( x for x in str(prediction) if x not in caracteres)\n","\n","  #Escribimos en el fichero\n","  f.write(\"\\n\" + str(fichero_test[\"id\"][cont]) + \"\\t\" + prediccion)\n","\n","  cont += 1\n","\n","f.close()"],"metadata":{"id":"5I-3uVZIpmgQ","executionInfo":{"status":"ok","timestamp":1652129789573,"user_tz":-120,"elapsed":45586,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","##   Evaluamos el sistema\n","\n"],"metadata":{"id":"dMn5Xt78XvdJ"}},{"cell_type":"code","source":["#Se ejecuta el script de prueba\n","%run -i scorer.py gold_label_test.tsv prediction_test.tsv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3EsoivoEyg94","executionInfo":{"status":"ok","timestamp":1652129818326,"user_tz":-120,"elapsed":1315,"user":{"displayName":"Roberto Gijón Liétor","userId":"17829929986840428329"}},"outputId":"07e5dc16-7db1-46d2-f51b-8c1b8110c891"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["GOLD_FILE: gold_label_test.tsv\n","PREDICTION_FILE: prediction_test.tsv\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"]},{"output_type":"stream","name":"stdout","text":["{'maf': 0.7041676707731491, 'map': 0.8848711769084219, 'mar': 0.6612039939286498, 'mif': 0.8679259150374835, 'mip': 0.8679259150374835, 'mir': 0.8679259150374835, 'avgf': 0.8417355962126334, 'avgp': 0.8725987780879091, 'avgr': 0.8679259150374835}\n"]}]}],"metadata":{"colab":{"name":"codigo_fuente.ipynb","provenance":[],"collapsed_sections":["JNtXMaXFVQfi","jB8Ym5SoY5d4"],"authorship_tag":"ABX9TyMBucPeqiEY65E4b2Ol22vF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}